{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4l0Ix6WcD10eQxg5qXggt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irfanfadhullah/Pytorch_Practice/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOdkl70og1EM"
      },
      "source": [
        "# **Pytorch Tutorial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tyo_Nc9g0iK"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ9P67R0hK6D",
        "outputId": "22a1b48d-a5bd-44ec-c986-3be287b254ff"
      },
      "source": [
        "x = torch.empty(2,2,2,3)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[4.6346e-15, 3.0716e-41, 7.0065e-44],\n",
            "          [6.8664e-44, 6.3058e-44, 6.7262e-44]],\n",
            "\n",
            "         [[7.9874e-44, 6.3058e-44, 6.8664e-44],\n",
            "          [7.2868e-44, 1.1771e-43, 6.8664e-44]]],\n",
            "\n",
            "\n",
            "        [[[7.1466e-44, 8.1275e-44, 7.2868e-44],\n",
            "          [7.5670e-44, 8.1275e-44, 7.4269e-44]],\n",
            "\n",
            "         [[7.9874e-44, 6.4460e-44, 7.7071e-44],\n",
            "          [6.8664e-44, 7.2868e-44, 6.8664e-44]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3bS6eifhPic",
        "outputId": "7e73b0ea-ef4a-4eec-9d18-b43aafc631a0"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6501, 0.6613],\n",
            "        [0.0313, 0.5260]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvzsYYQQhfbD",
        "outputId": "38e17e25-1342-4317-bd67-3ea881c0918f"
      },
      "source": [
        "x = torch.zeros(2,2)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxH4ecruhiQJ",
        "outputId": "4998a321-671c-44cb-ddc8-7e6652416bcb"
      },
      "source": [
        "x = torch.ones(2,2)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtaGp1EihjwL",
        "outputId": "4138e1b3-c59c-4757-8c48-16b0b6f0c9fa"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "print(x.dtype)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zUGlzjMhonf",
        "outputId": "78fc4109-48f3-4c7f-f509-bccd60a99a5b"
      },
      "source": [
        "x = torch.rand(2,2, dtype=torch.double)\n",
        "print(x.dtype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtxMZUpuht5f",
        "outputId": "b1fcd8c2-3185-4e10-f178-b540863e5a9d"
      },
      "source": [
        "x = torch.rand(2,2, dtype=torch.double)\n",
        "print(x.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZAw1AoNhy7-",
        "outputId": "a893584d-9600-4353-e7de-96cca08a090d"
      },
      "source": [
        "x = torch.rand(2,2, dtype=torch.double)\n",
        "print(x.dtype)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j25K0apAh7ML",
        "outputId": "1961e812-f20a-4ed5-9c10-9445a7b9b62d"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z = x+y\n",
        "print(z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3185, 0.8936],\n",
            "        [0.6553, 0.7716]])\n",
            "tensor([[0.0244, 0.2164],\n",
            "        [0.4013, 0.0587]])\n",
            "tensor([[0.3429, 1.1099],\n",
            "        [1.0566, 0.8303]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHrahg6miHoh",
        "outputId": "d5168952-3e24-4185-8eb5-56bc591f59cc"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z = torch.add(x,y)\n",
        "print(z)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8344, 0.3298],\n",
            "        [0.9334, 0.9944]])\n",
            "tensor([[0.5979, 0.8978],\n",
            "        [0.5640, 0.3365]])\n",
            "tensor([[1.4323, 1.2275],\n",
            "        [1.4975, 1.3309]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kjH6_X1iOkX",
        "outputId": "fe4754c1-0be4-40ba-862f-f602ad556aa7"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4260, 0.8888],\n",
            "        [0.8271, 0.5697]])\n",
            "tensor([[0.0564, 0.6268],\n",
            "        [0.9938, 0.0946]])\n",
            "tensor([[0.4824, 1.5155],\n",
            "        [1.8209, 0.6643]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ6RE6PPiUhi",
        "outputId": "c94e265b-a646-49e8-9ac6-0661392b9a9b"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "z = x*y\n",
        "z = torch.mul(x,y)\n",
        "print(z)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1548, 0.1038],\n",
            "        [0.8496, 0.0524]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBffou2cidn-",
        "outputId": "27017da0-d5e1-46b3-f386-7c1ced5fa6ad"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "z = x/y\n",
        "z = torch.div(x,y)\n",
        "print(z)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.6466, 2.4458],\n",
            "        [0.5709, 3.3250]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhqfkaRZijO2",
        "outputId": "5721ecb2-a0c3-4ef6-e742-4ce03a8e5349"
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:,0])\n",
        "print(x[1,:])\n",
        "print(x[1,1])\n",
        "print(x[1,1].item())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3461, 0.5299, 0.7150],\n",
            "        [0.8409, 0.9099, 0.3106],\n",
            "        [0.9868, 0.1132, 0.5675],\n",
            "        [0.7526, 0.3252, 0.2617],\n",
            "        [0.6625, 0.5640, 0.4000]])\n",
            "tensor([0.3461, 0.8409, 0.9868, 0.7526, 0.6625])\n",
            "tensor([0.8409, 0.9099, 0.3106])\n",
            "tensor(0.9099)\n",
            "0.9098909497261047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOxW7CaViuae",
        "outputId": "4b32c426-c809-485f-9dd2-b08ab76c06fe"
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "print(x)\n",
        "\n",
        "y = x.view(16)\n",
        "print(y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5145, 0.5093, 0.5735, 0.4786],\n",
            "        [0.7843, 0.9074, 0.7124, 0.4805],\n",
            "        [0.8395, 0.4313, 0.5674, 0.9499],\n",
            "        [0.1098, 0.7228, 0.7590, 0.7355]])\n",
            "tensor([0.5145, 0.5093, 0.5735, 0.4786, 0.7843, 0.9074, 0.7124, 0.4805, 0.8395,\n",
            "        0.4313, 0.5674, 0.9499, 0.1098, 0.7228, 0.7590, 0.7355])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVXnoXxWjKsR",
        "outputId": "da14c3cf-c5af-49dd-dc24-ce850047d950"
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "print(x)\n",
        "\n",
        "y = x.view(-1,8)\n",
        "print(y)\n",
        "print(y.size())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2258, 0.9495, 0.7405, 0.6110],\n",
            "        [0.1863, 0.0086, 0.3468, 0.1765],\n",
            "        [0.8306, 0.3897, 0.8478, 0.9005],\n",
            "        [0.9192, 0.5026, 0.3625, 0.3580]])\n",
            "tensor([[0.2258, 0.9495, 0.7405, 0.6110, 0.1863, 0.0086, 0.3468, 0.1765],\n",
            "        [0.8306, 0.3897, 0.8478, 0.9005, 0.9192, 0.5026, 0.3625, 0.3580]])\n",
            "torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyXh8-NJjSot"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXhKiqgijeYp",
        "outputId": "080c6979-1aff-426d-bc14-8a3406fb6055"
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "#same memmory location\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmw7EkV4joYh",
        "outputId": "7556ff63-0c4c-4607-9855-3f9d2233465f"
      },
      "source": [
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "\n",
        "a+=1\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLozddXQkI9H"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = torch.ones(5, device=device)\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device)\n",
        "  z = x+y\n",
        "  z = z.to(\"cpu\")\n",
        "  print(z)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_TO-e97k7W3",
        "outputId": "8797f265-bc9a-4218-8825-a55bbfd83a44"
      },
      "source": [
        "x = torch.ones(5, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9TL-wMslEBU"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1iYCmp6lNse"
      },
      "source": [
        "# **Gradient Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN85TW_ElSSV"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9uLRr8UlZue",
        "outputId": "637a6731-f0d8-4081-a7bf-aec3969e538f"
      },
      "source": [
        "x = torch.randn(3)\n",
        "print(x)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.3338,  0.7917,  0.0365])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze7N8aD6lcn4",
        "outputId": "b0a875ec-c9ed-431b-ce74-c0eea8cbc972"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print(y)\n",
        "z = y*y*2\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward() #dz/dx\n",
        "print(x.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.5627, -0.8155,  1.4772], requires_grad=True)\n",
            "tensor([0.4373, 1.1845, 3.4772], grad_fn=<AddBackward0>)\n",
            "tensor(9.1234, grad_fn=<MeanBackward0>)\n",
            "tensor([0.5831, 1.5793, 4.6363])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJCserUP06xn"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFwee5dD1BB2",
        "outputId": "1891592c-399c-401a-d83a-38481e0f1081"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print(y)\n",
        "z = y*y*2\n",
        "# z = z.mean()\n",
        "print(z)\n",
        "\n",
        "v = torch.tensor([0.1,1.0,0.001], dtype=torch.float32)\n",
        "z.backward(v) #dz/dx\n",
        "print(x.grad)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0996, 1.7514, 0.6771], requires_grad=True)\n",
            "tensor([2.0996, 3.7514, 2.6771], grad_fn=<AddBackward0>)\n",
            "tensor([ 8.8168, 28.1467, 14.3340], grad_fn=<MulBackward0>)\n",
            "tensor([8.3985e-01, 1.5006e+01, 1.0709e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn0OaCXU1BEB",
        "outputId": "dda26deb-2723-4916-cd3e-7c31569c14c5"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5248,  0.0601, -0.0169], requires_grad=True)\n",
            "tensor([-0.5248,  0.0601, -0.0169])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-xaPE0A2LUI",
        "outputId": "8a27592b-58ed-4e18-92d0-79104788be38"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "y = x.detach()\n",
        "print(y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4201,  1.3408,  0.9188], requires_grad=True)\n",
            "tensor([-0.4201,  1.3408,  0.9188])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7XOB1fS2TCO",
        "outputId": "3473c57c-24b7-4780-96f9-a66ecb8866f0"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)\n",
        "print(y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2516, -0.1256,  0.6445], requires_grad=True)\n",
            "tensor([2.2516, 1.8744, 2.6445])\n",
            "tensor([2.2516, 1.8744, 2.6445])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI_uU_zp2e3s",
        "outputId": "49ec451b-56d0-4f7c-8f11-76d19f8d210e"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "y = x+2\n",
        "print(y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.6112,  1.5946, -0.8432], requires_grad=True)\n",
            "tensor([2.6112, 3.5946, 1.1568], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oNnlW9V2kPs",
        "outputId": "a7e8a69d-6f33-4a17-b680-e32ea0212308"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpsV5NHz27F0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "bb73b8ee-c431-4fc6-d7ca-b7ee6e987cc6"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(weights, lr = 0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c3ed4ca56e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     40\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[1;32m     41\u001b[0m                             \u001b[0;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                             torch.typename(params))\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzfBSJjS3eHA"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "z.backward()\n",
        "\n",
        "weights.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwI7Gysj3eMh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR1LMsLn3nLt"
      },
      "source": [
        "#**Backpropagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zji0ocYB3p8V"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWfy6sZy5-xo"
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# Forward pass and compite the loss\n",
        "\n",
        "y_hat = w*x\n",
        "loss = (y_hat-y)**2\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEoIfSjM6TyL"
      },
      "source": [
        "#Backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIbEHu-D6erp"
      },
      "source": [
        "# update weights\n",
        "# next forward and backward\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "  w -= 0.01*w.grad\n",
        "\n",
        "#dont firget to zero the gradients\n",
        "w.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnGBf6Om7PLx"
      },
      "source": [
        "# **Gradient Descent with Autograd and Backpropagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCxHTwr7SJf"
      },
      "source": [
        "import numpy as np # in numpy"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWdZ6ysp7WZj",
        "outputId": "2e1c1801-ac61-4f93-eda4-590d2640b22b"
      },
      "source": [
        "# f = w+x\n",
        "# f = 2*x\n",
        "X = np.array([1,2,3,4], dtype=np.float32)\n",
        "Y = np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient# MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (2*x-y)\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5)}:.3f')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  dw = gradient(X,Y,y_pred)\n",
        "\n",
        "  # update weights\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5)}:.3f')\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.0:.3f\n",
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 2: w = 1.680, loss = 4.79999924\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 4: w = 1.949, loss = 0.12288000\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 6: w = 1.992, loss = 0.00314574\n",
            "epoch 7: w = 1.997, loss = 0.00050331\n",
            "epoch 8: w = 1.999, loss = 0.00008053\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 10: w = 2.000, loss = 0.00000206\n",
            "Prediction after training: f(5) = 9.998951268196105:.3f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Kmelp18BoB"
      },
      "source": [
        "import torch # in torch"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9BiWPy8BqX",
        "outputId": "ede0fe29-08b0-4354-f6db-b61b0e4d9ed7"
      },
      "source": [
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "Y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5)}:.3f')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = bacward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 10 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5)}:.3f')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.0:.3f\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 9.999998092651367:.3f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pi7JHRY8Bsn"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipSfYeGm_X3e"
      },
      "source": [
        "# **Training Pipeline: Model, Loss, and Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVrrfkBn8BvA"
      },
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training Loop\n",
        "#   - forward pass: compute prediction\n",
        "#   - backward pass: gradients\n",
        "#   - update weights"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pBS7nTm8Bxa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__qa-u_I8Bz-",
        "outputId": "df2a8c7f-75c7-4d09-ce4b-8eeb65a84789"
      },
      "source": [
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "Y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5)}:.3f')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = bacward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5)}:.3f')\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.0:.3f\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 9.999998092651367:.3f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEqER6XAeO4",
        "outputId": "70b2de6a-d349-4b14-edf7-d02c05497d89"
      },
      "source": [
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    #define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "  \n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.001\n",
        "n_iters = 200\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = bacward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 ==0:\n",
        "    [w,b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training: f(5) = 0.841\n",
            "epoch 1: w = 0.383, loss = 28.82069969\n",
            "epoch 11: w = 0.651, loss = 20.58385658\n",
            "epoch 21: w = 0.877, loss = 14.70248985\n",
            "epoch 31: w = 1.068, loss = 10.50299644\n",
            "epoch 41: w = 1.229, loss = 7.50440884\n",
            "epoch 51: w = 1.365, loss = 5.36330414\n",
            "epoch 61: w = 1.480, loss = 3.83446431\n",
            "epoch 71: w = 1.578, loss = 2.74280024\n",
            "epoch 81: w = 1.660, loss = 1.96329212\n",
            "epoch 91: w = 1.729, loss = 1.40667224\n",
            "epoch 101: w = 1.788, loss = 1.00920129\n",
            "epoch 111: w = 1.837, loss = 0.72536707\n",
            "epoch 121: w = 1.879, loss = 0.52267295\n",
            "epoch 131: w = 1.914, loss = 0.37791577\n",
            "epoch 141: w = 1.944, loss = 0.27452660\n",
            "epoch 151: w = 1.969, loss = 0.20067596\n",
            "epoch 161: w = 1.990, loss = 0.14791676\n",
            "epoch 171: w = 2.008, loss = 0.11021705\n",
            "epoch 181: w = 2.023, loss = 0.08327112\n",
            "epoch 191: w = 2.035, loss = 0.06400378\n",
            "Prediction after training: f(5) = 9.894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVPNfXTKB6Vx"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpSsZ1lADlee"
      },
      "source": [
        "# **Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8WazlZLqDkRI",
        "outputId": "6bd336fc-8699-440d-c1c8-5e7bd819465a"
      },
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training Loop\n",
        "#   - forward pass: compute prediction\n",
        "#   - backward pass: gradients\n",
        "#   - update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise=20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0],1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1)model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2)loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# 3)training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10==0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4409.6724\n",
            "epoch: 20, loss = 3289.8235\n",
            "epoch: 30, loss = 2479.4556\n",
            "epoch: 40, loss = 1892.4198\n",
            "epoch: 50, loss = 1466.7510\n",
            "epoch: 60, loss = 1157.8115\n",
            "epoch: 70, loss = 933.4040\n",
            "epoch: 80, loss = 770.2734\n",
            "epoch: 90, loss = 651.6031\n",
            "epoch: 100, loss = 565.2197\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSZBo2iuF_ga"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWzLW0uJGetM"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmXy2d8gF_jD"
      },
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training Loop\n",
        "#   - forward pass: compute prediction\n",
        "#   - backward pass: gradients\n",
        "#   - update weights"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmztSGWLF_ld"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OQjLVPRF_n1",
        "outputId": "76cabc38-cc54-4cf2-c732-d26494964baf"
      },
      "source": [
        "# 0) prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X,y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state= 1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) model\n",
        "#   - f = wx+b sigmoid in the end\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# 2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# 3) training loop\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "  \n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  \n",
        "  # update\n",
        "  optimizer.step()\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10==0:\n",
        "    print(f'epoch: {epoch+1}, loss:{loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum()/ float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "569 30\n",
            "epoch: 10, loss:0.4931\n",
            "epoch: 20, loss:0.4304\n",
            "epoch: 30, loss:0.3855\n",
            "epoch: 40, loss:0.3516\n",
            "epoch: 50, loss:0.3249\n",
            "epoch: 60, loss:0.3032\n",
            "epoch: 70, loss:0.2851\n",
            "epoch: 80, loss:0.2698\n",
            "epoch: 90, loss:0.2567\n",
            "epoch: 100, loss:0.2452\n",
            "epoch: 110, loss:0.2350\n",
            "epoch: 120, loss:0.2260\n",
            "epoch: 130, loss:0.2179\n",
            "epoch: 140, loss:0.2106\n",
            "epoch: 150, loss:0.2040\n",
            "epoch: 160, loss:0.1979\n",
            "epoch: 170, loss:0.1924\n",
            "epoch: 180, loss:0.1873\n",
            "epoch: 190, loss:0.1825\n",
            "epoch: 200, loss:0.1782\n",
            "epoch: 210, loss:0.1741\n",
            "epoch: 220, loss:0.1703\n",
            "epoch: 230, loss:0.1667\n",
            "epoch: 240, loss:0.1634\n",
            "epoch: 250, loss:0.1603\n",
            "epoch: 260, loss:0.1574\n",
            "epoch: 270, loss:0.1546\n",
            "epoch: 280, loss:0.1520\n",
            "epoch: 290, loss:0.1495\n",
            "epoch: 300, loss:0.1472\n",
            "accuracy = 0.9298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQ3WrsJKZGC"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jBX5bhmkBtx"
      },
      "source": [
        "# **Batch Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVZA9qHOrcS5",
        "outputId": "b90ddee6-6f49-4870-9bb8-0436a7fd97c0"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 14:20:02--  https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10889 (11K) [text/plain]\n",
            "Saving to: ‘wine.csv’\n",
            "\n",
            "\rwine.csv              0%[                    ]       0  --.-KB/s               \rwine.csv            100%[===================>]  10.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-14 14:20:02 (95.9 MB/s) - ‘wine.csv’ saved [10889/10889]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXtsYHlqkCKU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torchvision"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v40wVdPHrHpV",
        "outputId": "a49d1745-cf17-420f-8f39-03a13e5d95eb"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('/content/wine.csv', delimiter = ',', dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]])\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #dataset\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)  \n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAZQUigmsZ0o",
        "outputId": "d972c49c-8ba5-4b8f-a196-f1164563170b"
      },
      "source": [
        "dataloader = DataLoader(dataset = dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, labels)  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2080e+01, 1.1300e+00, 2.5100e+00, 2.4000e+01, 7.8000e+01, 2.0000e+00,\n",
            "         1.5800e+00, 4.0000e-01, 1.4000e+00, 2.2000e+00, 1.3100e+00, 2.7200e+00,\n",
            "         6.3000e+02],\n",
            "        [1.2070e+01, 2.1600e+00, 2.1700e+00, 2.1000e+01, 8.5000e+01, 2.6000e+00,\n",
            "         2.6500e+00, 3.7000e-01, 1.3500e+00, 2.7600e+00, 8.6000e-01, 3.2800e+00,\n",
            "         3.7800e+02],\n",
            "        [1.3710e+01, 1.8600e+00, 2.3600e+00, 1.6600e+01, 1.0100e+02, 2.6100e+00,\n",
            "         2.8800e+00, 2.7000e-01, 1.6900e+00, 3.8000e+00, 1.1100e+00, 4.0000e+00,\n",
            "         1.0350e+03],\n",
            "        [1.3050e+01, 1.6500e+00, 2.5500e+00, 1.8000e+01, 9.8000e+01, 2.4500e+00,\n",
            "         2.4300e+00, 2.9000e-01, 1.4400e+00, 4.2500e+00, 1.1200e+00, 2.5100e+00,\n",
            "         1.1050e+03]]) tensor([[2.],\n",
            "        [2.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1rrpqEPs3zY",
        "outputId": "924365e2-51d0-4eae-b2b9-9b04ff804776"
      },
      "source": [
        "dataloader = DataLoader(dataset = dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bkP84XttStd",
        "outputId": "76e5b1e9-0d01-46d4-a65c-5a3f006577ea"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    if (i+1)%5==0:\n",
        "      print(f'epoch: {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch: 1/2, step 45/45, inputs torch.Size([2, 13])\n",
            "epoch: 2/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch: 2/2, step 45/45, inputs torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zfjFUBt2_J"
      },
      "source": [
        "# torchvision.datasets.MNIST()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuPWHcQGuAvM"
      },
      "source": [
        "# **Dataset Transforms**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVrX0Q0PuA6n"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torchvision"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYFShkbpunqz",
        "outputId": "6a5efd0d-8af6-4e56-b08d-f1dc4e74e66f"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('/content/wine.csv', delimiter = ',', dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]]\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #dataset\n",
        "    sample =  self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor():\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, target\n",
        "\n",
        "dataset = WineDataset(transform = None)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
        "dataset = WineDataset(transform = composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
            "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
            "        2.1300e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSDjoixvs8d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT0J2XWB1ui4"
      },
      "source": [
        "#**Softmax and Cross-Entropy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2TXJtDI1yXn",
        "outputId": "75ba6fe2-eefc-4264-b5a9-ed08b8baf435"
      },
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0,1.0,0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0,1.0,0.1])\n",
        "outputs = torch.softmax(x, dim = 0)\n",
        "print('softmax tensor:', outputs)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax tensor: tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW50Ff4G2UdR",
        "outputId": "7244889b-a636-4afa-ac2d-6fbc19ac1caf"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#3 samples\n",
        "\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "# nsamples x nclasses = 3 x 3\n",
        "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1],[0.1, 1.0, 2.1],[0.1, 3.0, 0.1]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(predictions1, predictions2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3018244206905365\n",
            "1.6241613626480103\n",
            "tensor([2, 0, 1]) tensor([0, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkvstwgi4dtc"
      },
      "source": [
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC-OfxMf6DPk"
      },
      "source": [
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRTU6DSK6Yv8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axXa3smk6g5K"
      },
      "source": [
        "# **Activation Fnction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qfPMIx8iKO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_6g7MER6hD9"
      },
      "source": [
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "        # # sigmoid at the end\n",
        "        # y_pred = torch.sigmoid(out)\n",
        "        # return y_pred\n",
        "\n",
        "# model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "# criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}